"""
Property-based tests for error handling and recovery
Feature: customer-onboarding-agent, Property 13: Error Handling and Recovery
Validates: Requirements 1.4, 1.5, 9.2
"""

import pytest
import asyncio
import json
from unittest.mock import AsyncMock, patch, MagicMock
from hypothesis import given, strategies as st, settings, assume, HealthCheck
from datetime import datetime
from typing import Dict, Any, Optional
from io import BytesIO

from app.services.scaledown_service import ScaleDownService
from app.services.claude_client import ClaudeAPIClient
from app.services.document_processor import DocumentProcessor
from fastapi import UploadFile, HTTPException
from anthropic._exceptions import (
    RateLimitError, 
    APIError, 
    AuthenticationError,
    BadRequestError,
    InternalServerError
)


# Hypothesis strategies for generating test data
document_content_strategy = st.text(
    alphabet=st.characters(whitelist_categories=("Lu", "Ll", "Nd", "Zs", "Po")),
    min_size=50,
    max_size=2000
).filter(lambda x: len(x.strip()) > 20)

filename_strategy = st.builds(
    lambda name, ext: f"{name}.{ext}",
    name=st.text(
        alphabet=st.characters(whitelist_categories=("Lu", "Ll", "Nd")),
        min_size=1,
        max_size=30
    ).filter(lambda x: x and not x.startswith('.')),
    ext=st.sampled_from(["txt", "pdf", "doc", "docx", "md"])
)

# Strategy for invalid file types
invalid_filename_strategy = st.builds(
    lambda name, ext: f"{name}.{ext}",
    name=st.text(
        alphabet=st.characters(whitelist_categories=("Lu", "Ll", "Nd")),
        min_size=1,
        max_size=30
    ).filter(lambda x: x and not x.startswith('.')),
    ext=st.sampled_from(["exe", "bin", "jpg", "png", "mp4", "zip", "unknown"])
)

# Strategy for file sizes that should be invalid (too small or too large)
invalid_file_size_strategy = st.one_of(
    st.just(0),  # Too small
    st.integers(min_value=11 * 1024 * 1024, max_value=20 * 1024 * 1024)  # Too large
)

# Helper function to create mock exceptions
def create_mock_exception(exception_class, message):
    """Create properly structured mock exceptions for Anthropic API"""
    if exception_class in [RateLimitError, AuthenticationError, BadRequestError, InternalServerError]:
        # These use response parameter
        mock_response = MagicMock()
        mock_response.request = MagicMock()
        return exception_class(message, response=mock_response, body=None)
    elif exception_class == APIError:
        # APIError uses request parameter
        mock_request = MagicMock()
        return exception_class(message, request=mock_request, body=None)
    else:
        return exception_class(message)

# Strategy for Claude API errors
claude_error_strategy = st.builds(
    create_mock_exception,
    exception_class=st.sampled_from([
        RateLimitError,
        APIError, 
        AuthenticationError,
        BadRequestError,
        InternalServerError,
        Exception
    ]),
    message=st.text(min_size=10, max_size=100)
)

# Strategy for retry counts
retry_count_strategy = st.integers(min_value=1, max_value=5)


def create_mock_upload_file(
    filename: str, 
    content: str, 
    content_type: str = "text/plain",
    file_size: Optional[int] = None
) -> UploadFile:
    """Create a mock UploadFile for testing"""
    file_obj = BytesIO(content.encode('utf-8'))
    file_obj.name = filename
    
    upload_file = UploadFile(
        filename=filename,
        file=file_obj
    )
    
    # Mock content_type as a property since it's read-only
    type(upload_file).content_type = property(lambda self: content_type)
    
    # Set file size if provided
    if file_size is not None:
        upload_file.size = file_size
    
    # Mock the file methods
    upload_file.read = AsyncMock(return_value=content.encode('utf-8'))
    upload_file.seek = AsyncMock()
    upload_file.close = AsyncMock()
    
    return upload_file


@pytest.mark.asyncio
@given(
    filename=invalid_filename_strategy,
    content=document_content_strategy
)
@settings(max_examples=20, deadline=None, suppress_health_check=[HealthCheck.function_scoped_fixture])
async def test_property_document_validation_error_handling(filename, content):
    """
    **Feature: customer-onboarding-agent, Property 13: Error Handling and Recovery**
    **Validates: Requirements 1.5**
    
    For any document with unsupported format, the ScaleDown_Engine should validate 
    the document before processing and return descriptive error messages while 
    maintaining system stability.
    """
    # Ensure we have meaningful content
    assume(len(content.strip()) >= 20)
    
    # Create mock upload file with invalid format
    upload_file = create_mock_upload_file(filename, content, "application/octet-stream")
    
    # Create document processor
    processor = DocumentProcessor()
    
    # **Property 13 Verification: Document Format Validation**
    is_valid, error_message = await processor.validate_file(upload_file)
    
    # Should reject invalid file types
    assert not is_valid, \
        f"Document with unsupported format '{filename}' should be rejected"
    
    # **Property 13 Verification: Descriptive Error Messages**
    assert error_message is not None, \
        "Validation failure must provide descriptive error message"
    
    assert isinstance(error_message, str), \
        "Error message must be a string"
    
    assert len(error_message.strip()) > 0, \
        "Error message must not be empty"
    
    # Error message should be descriptive and mention the issue
    error_lower = error_message.lower()
    assert any(keyword in error_lower for keyword in [
        "unsupported", "format", "type", "extension", "invalid"
    ]), f"Error message should be descriptive about format issue: '{error_message}'"
    
    # **Property 13 Verification: System Stability**
    # The validation should not raise exceptions, just return error info
    # This demonstrates system stability - errors are handled gracefully
    
    # Test that we can call validation multiple times without issues
    is_valid_2, error_message_2 = await processor.validate_file(upload_file)
    assert not is_valid_2, "Validation should be consistent"
    assert error_message_2 is not None, "Error message should be consistent"


@pytest.mark.asyncio
@given(
    filename=filename_strategy,
    content=document_content_strategy,
    file_size=invalid_file_size_strategy
)
@settings(max_examples=20, deadline=None, suppress_health_check=[HealthCheck.function_scoped_fixture])
async def test_property_file_size_validation_error_handling(filename, content, file_size):
    """
    **Feature: customer-onboarding-agent, Property 13: Error Handling and Recovery**
    **Validates: Requirements 1.5**
    
    For any document with invalid file size (too large or too small), the system 
    should validate and return descriptive error messages while maintaining stability.
    """
    # All file sizes in invalid_file_size_strategy are invalid by design
    
    # Create mock upload file with problematic size
    upload_file = create_mock_upload_file(filename, content, "text/plain", file_size)
    
    # Create document processor
    processor = DocumentProcessor()
    
    # **Property 13 Verification: File Size Validation**
    is_valid, error_message = await processor.validate_file(upload_file)
    
    # Should reject files with invalid sizes
    assert not is_valid, \
        f"Document with size {file_size} bytes should be rejected"
    
    # **Property 13 Verification: Descriptive Error Messages for Size Issues**
    assert error_message is not None, \
        "Size validation failure must provide descriptive error message"
    
    assert isinstance(error_message, str), \
        "Error message must be a string"
    
    assert len(error_message.strip()) > 0, \
        "Error message must not be empty"
    
    # Error message should mention either size issues OR format issues (validation order may vary)
    error_lower = error_message.lower()
    size_keywords = ["size", "bytes", "maximum", "minimum", "exceeds", "below"]
    format_keywords = ["extension", "format", "type", "match", "unsupported"]
    
    has_size_keywords = any(keyword in error_lower for keyword in size_keywords)
    has_format_keywords = any(keyword in error_lower for keyword in format_keywords)
    
    assert has_size_keywords or has_format_keywords, \
        f"Error message should describe validation issue (size or format): '{error_message}'"
    
    # If it's a size error, should include the actual file size
    if has_size_keywords:
        assert str(file_size) in error_message, \
            f"Size error message should include actual file size {file_size}"
    
    # **Property 13 Verification: System Stability Under Size Validation**
    # Multiple validations should work consistently
    for _ in range(3):
        is_valid_repeat, error_repeat = await processor.validate_file(upload_file)
        assert not is_valid_repeat, "Size validation should be consistent"
        assert error_repeat is not None, "Error message should be consistent"


@pytest.mark.asyncio
@given(
    filename=filename_strategy,
    content=document_content_strategy,
    error_type=claude_error_strategy,
    retry_count=retry_count_strategy
)
@settings(max_examples=20, deadline=None, suppress_health_check=[HealthCheck.function_scoped_fixture])
async def test_property_claude_api_error_handling_and_retry(filename, content, error_type, retry_count):
    """
    **Feature: customer-onboarding-agent, Property 13: Error Handling and Recovery**
    **Validates: Requirements 1.4, 9.2**
    
    For any Claude API error (including rate limits), the system should handle errors 
    gracefully with appropriate retry mechanisms and return descriptive error messages 
    while maintaining system stability.
    """
    # Ensure meaningful content
    assume(len(content.strip()) >= 50)
    
    # Track retry attempts
    attempt_count = 0
    
    async def failing_api_call(*args, **kwargs):
        nonlocal attempt_count
        attempt_count += 1
        
        # Simulate retries for rate limits and server errors
        if isinstance(error_type, (RateLimitError, InternalServerError)):
            if attempt_count < retry_count:
                raise error_type
            else:
                # After retries, still fail
                raise error_type
        else:
            # Other errors fail immediately
            raise error_type
    
    # Mock the Claude client with error simulation
    with patch.object(ClaudeAPIClient, '__init__', return_value=None), \
         patch('asyncio.sleep', new_callable=AsyncMock):  # Speed up retries
        
        client = ClaudeAPIClient()
        # Set up required attributes that would normally be set in __init__
        client.max_retries = retry_count
        client.base_delay = 1.0
        client.max_delay = 60.0
        client.model = "claude-3-haiku-20240307"
        client.max_tokens = 4000
        
        # Mock the actual Anthropic client
        client.client = MagicMock()
        client.client.messages = MagicMock()
        client.client.messages.create = AsyncMock(side_effect=failing_api_call)
        
        # **Property 13 Verification: Error Handling with Descriptive Messages**
        with pytest.raises(HTTPException) as exc_info:
            await client.process_document_single_call(content=content, filename=filename)
        
        # **Property 13 Verification: Descriptive Error Messages**
        error_detail = exc_info.value.detail
        assert isinstance(error_detail, str), \
            "Error detail must be a string"
        
        assert len(error_detail.strip()) > 0, \
            "Error detail must not be empty"
        
        # Error should be descriptive about the type of failure
        error_lower = error_detail.lower()
        
        if isinstance(error_type, RateLimitError):
            # **Property 13 Verification: Rate Limit Error Handling (Requirement 9.2)**
            assert any(keyword in error_lower for keyword in [
                "rate limit", "rate", "limit", "try again"
            ]), f"Rate limit error should be descriptive: '{error_detail}'"
            
            # Should have appropriate HTTP status code
            assert exc_info.value.status_code == 429, \
                "Rate limit errors should return 429 status code"
            
            # **Property 13 Verification: Retry Mechanism for Rate Limits**
            # For rate limits, should retry up to max_retries
            expected_attempts = min(retry_count, client.max_retries)
            assert attempt_count >= expected_attempts, \
                f"Rate limit should trigger retries (expected >= {expected_attempts}, got {attempt_count})"
        
        elif isinstance(error_type, AuthenticationError):
            assert any(keyword in error_lower for keyword in [
                "authentication", "auth", "api key"
            ]), f"Auth error should be descriptive: '{error_detail}'"
            
            assert exc_info.value.status_code == 401, \
                "Auth errors should return 401 status code"
            
            # Auth errors should not retry
            assert attempt_count == 1, \
                "Authentication errors should not retry"
        
        elif isinstance(error_type, BadRequestError):
            assert any(keyword in error_lower for keyword in [
                "invalid", "bad", "request"
            ]), f"Bad request error should be descriptive: '{error_detail}'"
            
            assert exc_info.value.status_code == 400, \
                "Bad request errors should return 400 status code"
            
            # Bad requests should not retry
            assert attempt_count == 1, \
                "Bad request errors should not retry"
        
        elif isinstance(error_type, InternalServerError):
            assert any(keyword in error_lower for keyword in [
                "server", "unavailable", "try again"
            ]), f"Server error should be descriptive: '{error_detail}'"
            
            assert exc_info.value.status_code == 502, \
                "Server errors should return 502 status code"
            
            # **Property 13 Verification: Retry Mechanism for Server Errors**
            expected_attempts = min(retry_count, client.max_retries)
            assert attempt_count >= expected_attempts, \
                f"Server errors should trigger retries (expected >= {expected_attempts}, got {attempt_count})"
        
        else:
            # Generic API or unexpected errors
            assert any(keyword in error_lower for keyword in [
                "error", "failed", "processing"
            ]), f"Generic error should be descriptive: '{error_detail}'"
        
        # **Property 13 Verification: System Stability**
        # The system should not crash, just return proper HTTP exceptions
        assert isinstance(exc_info.value, HTTPException), \
            "Errors should be converted to proper HTTP exceptions"


@pytest.mark.asyncio
@given(
    filename=filename_strategy,
    content=document_content_strategy
)
@settings(max_examples=20, deadline=None, suppress_health_check=[HealthCheck.function_scoped_fixture])
async def test_property_document_processing_failure_stability(filename, content):
    """
    **Feature: customer-onboarding-agent, Property 13: Error Handling and Recovery**
    **Validates: Requirements 1.4**
    
    For any document processing failure, the ScaleDown_Engine should maintain system 
    stability and return descriptive error messages without crashing or corrupting state.
    """
    # Ensure meaningful content
    assume(len(content.strip()) >= 30)
    
    # Create mock upload file
    upload_file = create_mock_upload_file(filename, content)
    
    # Mock various failure scenarios in the processing pipeline
    failure_scenarios = [
        ("content_extraction", "Failed to extract content"),
        ("claude_processing", "Claude API processing failed"),
        ("response_parsing", "Failed to parse Claude response"),
        ("database_storage", "Database storage failed")
    ]
    
    for scenario_name, error_message in failure_scenarios:
        # Create ScaleDown service
        service = ScaleDownService()
        
        # Mock different failure points
        if scenario_name == "content_extraction":
            with patch.object(DocumentProcessor, 'extract_content') as mock_extract:
                mock_extract.side_effect = HTTPException(
                    status_code=400, 
                    detail=error_message
                )
                
                # **Property 13 Verification: Content Extraction Error Handling**
                with pytest.raises(HTTPException) as exc_info:
                    await mock_extract(upload_file)
                
                # **Property 13 Verification: Descriptive Error Messages**
                assert exc_info.value.detail == error_message, \
                    "Error message should be preserved through the pipeline"
                
                assert exc_info.value.status_code == 400, \
                    "HTTP status code should be appropriate"
        
        elif scenario_name == "claude_processing":
            with patch.object(ClaudeAPIClient, '__init__', return_value=None), \
                 patch.object(ClaudeAPIClient, 'process_document_single_call') as mock_process:
                
                mock_process.side_effect = HTTPException(
                    status_code=502,
                    detail=error_message
                )
                
                service.claude_client = MagicMock()
                service.claude_client.process_document_single_call = mock_process
                
                # **Property 13 Verification: Claude Processing Error Handling**
                with pytest.raises(HTTPException) as exc_info:
                    await service.claude_client.process_document_single_call(
                        content=content, 
                        filename=filename
                    )
                
                # **Property 13 Verification: Error Message Propagation**
                assert exc_info.value.detail == error_message, \
                    "Claude processing errors should be properly propagated"
                
                assert exc_info.value.status_code == 502, \
                    "Claude processing errors should have appropriate status code"
        
        # **Property 13 Verification: System Stability After Errors**
        # After each error scenario, the service should still be functional
        # Test that we can create a new service instance without issues
        new_service = ScaleDownService()
        assert new_service is not None, \
            f"System should remain stable after {scenario_name} failure"
        
        # Test that document processor is still functional
        processor = DocumentProcessor()
        is_valid, _ = await processor.validate_file(upload_file)
        # This should work regardless of previous failures
        assert isinstance(is_valid, bool), \
            f"Document validation should work after {scenario_name} failure"


@pytest.mark.asyncio
@given(
    filename=filename_strategy,
    content=document_content_strategy,
    consecutive_failures=st.integers(min_value=2, max_value=5)
)
@settings(max_examples=10, deadline=None, suppress_health_check=[HealthCheck.function_scoped_fixture])
async def test_property_consecutive_error_handling_stability(filename, content, consecutive_failures):
    """
    **Feature: customer-onboarding-agent, Property 13: Error Handling and Recovery**
    **Validates: Requirements 1.4, 9.2**
    
    For any sequence of consecutive processing failures, the system should maintain 
    stability and continue to provide descriptive error messages without degradation.
    """
    # Ensure meaningful content
    assume(len(content.strip()) >= 30)
    
    # Create mock upload file
    upload_file = create_mock_upload_file(filename, content)
    
    # Test consecutive failures
    error_messages = []
    
    for failure_num in range(consecutive_failures):
        # Create fresh service instance for each attempt
        service = ScaleDownService()
        
        # Mock Claude client to fail
        with patch.object(ClaudeAPIClient, '__init__', return_value=None), \
             patch.object(ClaudeAPIClient, 'process_document_single_call') as mock_process:
            
            failure_message = f"Processing failure #{failure_num + 1}"
            mock_process.side_effect = HTTPException(
                status_code=500,
                detail=failure_message
            )
            
            service.claude_client = MagicMock()
            service.claude_client.process_document_single_call = mock_process
            
            # **Property 13 Verification: Consecutive Error Handling**
            with pytest.raises(HTTPException) as exc_info:
                await service.claude_client.process_document_single_call(
                    content=content,
                    filename=filename
                )
            
            # **Property 13 Verification: Error Message Quality Consistency**
            error_detail = exc_info.value.detail
            error_messages.append(error_detail)
            
            assert isinstance(error_detail, str), \
                f"Error message {failure_num + 1} must be a string"
            
            assert len(error_detail.strip()) > 0, \
                f"Error message {failure_num + 1} must not be empty"
            
            assert failure_message in error_detail, \
                f"Error message {failure_num + 1} should contain expected content"
            
            # **Property 13 Verification: HTTP Status Code Consistency**
            assert exc_info.value.status_code == 500, \
                f"Error {failure_num + 1} should have consistent status code"
    
    # **Property 13 Verification: System Stability After Multiple Failures**
    # After multiple consecutive failures, system should still be functional
    
    # Test that we can still create new service instances
    final_service = ScaleDownService()
    assert final_service is not None, \
        "System should remain stable after consecutive failures"
    
    # Test that document processor still works
    processor = DocumentProcessor()
    is_valid, validation_error = await processor.validate_file(upload_file)
    assert isinstance(is_valid, bool), \
        "Document validation should work after consecutive failures"
    
    # **Property 13 Verification: Error Message Consistency**
    # All error messages should be properly formatted
    assert len(error_messages) == consecutive_failures, \
        "Should have collected all error messages"
    
    for i, msg in enumerate(error_messages):
        assert isinstance(msg, str) and len(msg.strip()) > 0, \
            f"Error message {i + 1} should be valid string"


@pytest.mark.asyncio
@given(
    filename=filename_strategy,
    content=document_content_strategy
)
@settings(max_examples=10, deadline=None, suppress_health_check=[HealthCheck.function_scoped_fixture])
async def test_property_error_recovery_after_success(filename, content):
    """
    **Feature: customer-onboarding-agent, Property 13: Error Handling and Recovery**
    **Validates: Requirements 1.4**
    
    For any system that experiences errors and then recovers, the error handling 
    should not interfere with subsequent successful operations.
    """
    # Ensure meaningful content
    assume(len(content.strip()) >= 50)
    
    # Create mock upload file
    upload_file = create_mock_upload_file(filename, content)
    
    # Successful response for recovery test
    success_response = {
        "summary": f"Summary of {filename}: {content[:100]}...",
        "tasks": ["Task 1: Process document", "Task 2: Review content"],
        "processing_time": 1.5,
        "model_used": "claude-3-haiku-20240307"
    }
    
    # Test error followed by success
    service = ScaleDownService()
    
    # First attempt: simulate failure
    with patch.object(ClaudeAPIClient, '__init__', return_value=None), \
         patch.object(ClaudeAPIClient, 'process_document_single_call') as mock_process_fail:
        
        mock_process_fail.side_effect = HTTPException(
            status_code=500,
            detail="Temporary processing failure"
        )
        
        service.claude_client = MagicMock()
        service.claude_client.process_document_single_call = mock_process_fail
        
        # **Property 13 Verification: Initial Error Handling**
        with pytest.raises(HTTPException) as exc_info:
            await service.claude_client.process_document_single_call(
                content=content,
                filename=filename
            )
        
        assert "Temporary processing failure" in exc_info.value.detail, \
            "Initial error should be properly handled"
    
    # Second attempt: simulate success (recovery)
    with patch.object(ClaudeAPIClient, '__init__', return_value=None), \
         patch.object(ClaudeAPIClient, 'process_document_single_call') as mock_process_success:
        
        mock_process_success.return_value = success_response
        
        # Create new service instance (simulating recovery)
        recovered_service = ScaleDownService()
        recovered_service.claude_client = MagicMock()
        recovered_service.claude_client.process_document_single_call = mock_process_success
        
        # **Property 13 Verification: Recovery After Error**
        result = await recovered_service.claude_client.process_document_single_call(
            content=content,
            filename=filename
        )
        
        # **Property 13 Verification: Successful Operation After Recovery**
        assert result == success_response, \
            "System should work normally after error recovery"
        
        assert 'summary' in result, \
            "Recovered operation should return complete response"
        
        assert 'tasks' in result, \
            "Recovered operation should return all required fields"
        
        assert len(result['tasks']) > 0, \
            "Recovered operation should return meaningful data"
    
    # **Property 13 Verification: System State Consistency**
    # After error and recovery, system should be in clean state
    final_service = ScaleDownService()
    assert final_service is not None, \
        "System should be in clean state after error recovery cycle"
    
    # Document processor should still work normally
    processor = DocumentProcessor()
    is_valid, _ = await processor.validate_file(upload_file)
    assert isinstance(is_valid, bool), \
        "Document validation should work normally after error recovery"


@pytest.mark.asyncio
async def test_property_error_handling_meta_verification():
    """
    **Feature: customer-onboarding-agent, Property 13: Error Handling and Recovery**
    **Validates: Requirements 1.4, 1.5, 9.2**
    
    Meta-test to verify that our error handling property tests correctly identify 
    and validate error scenarios. This ensures the test framework itself is robust.
    """
    # Test that we can properly simulate and catch different error types
    error_types = [
        (create_mock_exception(RateLimitError, "Test rate limit"), 429),
        (create_mock_exception(AuthenticationError, "Test auth error"), 401),
        (create_mock_exception(BadRequestError, "Test bad request"), 400),
        (create_mock_exception(InternalServerError, "Test server error"), 502),
        (create_mock_exception(APIError, "Test API error"), 502)
    ]
    
    for error_type, expected_status in error_types:
        with patch.object(ClaudeAPIClient, '__init__', return_value=None):
            
            client = ClaudeAPIClient()
            # Set up required attributes that would normally be set in __init__
            client.max_retries = 3
            client.base_delay = 1.0
            client.max_delay = 60.0
            client.model = "claude-3-haiku-20240307"
            client.max_tokens = 4000
            
            # Mock the actual Anthropic client
            client.client = MagicMock()
            client.client.messages = MagicMock()
            client.client.messages.create = AsyncMock(side_effect=error_type)
            
            # Verify that each error type is properly handled
            with pytest.raises(HTTPException) as exc_info:
                await client.process_document_single_call(
                    content="test content",
                    filename="test.txt"
                )
            
            # Verify proper status code mapping
            assert exc_info.value.status_code == expected_status, \
                f"Error type {type(error_type).__name__} should map to status {expected_status}"
            
            # Verify error message is descriptive
            assert len(exc_info.value.detail) > 0, \
                f"Error type {type(error_type).__name__} should have descriptive message"
    
    # Test document validation error scenarios
    processor = DocumentProcessor()
    
    # Test invalid file type
    invalid_file = create_mock_upload_file("test.exe", "content", "application/octet-stream")
    is_valid, error_msg = await processor.validate_file(invalid_file)
    assert not is_valid, "Invalid file type should be rejected"
    assert error_msg is not None, "Invalid file should have error message"
    
    # Test oversized file
    large_file = create_mock_upload_file("test.txt", "content", "text/plain", 20 * 1024 * 1024)
    is_valid, error_msg = await processor.validate_file(large_file)
    assert not is_valid, "Oversized file should be rejected"
    assert error_msg is not None, "Oversized file should have error message"
    
    print("âœ“ Error handling property test framework verification complete")